from abc import abstractmethod, ABC
import sys
from typing import Generator, Generic, TypeVar, Optional

import stanza
from stanza.models.common.doc import Sentence as StanzaSentence

from corpus_views import PickleStanzaDocCorpusView

T = TypeVar('T')

class CorpusFilterWriter(ABC, Generic[T]):
    """Reads in a corpus, partitions it based on some predicate, and writes one or more of the partitioned corpuses to
    file.

    A CorpusFilterWriter consists of three entities:
        (1) An Iterable that yields input entities of type T (typically, corresponding to sentences)
        (2) A predicate function that accepts an element of type T from the Iterable and returns a boolean.
        (3) A function that accepts an element of type T from the Iterable and the result of evaluating the predicate
            on that element, and defines if/how to write it to file.

    Subclasses of CorpusFilter should concretely implement the logic of those entities (adjusting their constructors
    accordingly).
    """
    def filter_write(self):
        for sent in self._get_sents():
            self._write(sent, reject=self._exclude_sent(sent))

    def __enter__(self):
        """Used by Python's `with` statement.
        """
        return self

    def close(self):
        """Subclasses may do any cleanup logic necessary at the end of a `with` block here.
        """
        pass

    def __exit__(self, type, value, traceback):
        """Used by Python's `with` statement.
        """
        self.close()

    @abstractmethod
    def _exclude_sent(self, sent: T) -> bool:
        """Predicate that determines whether the basic atoms of this corpus (i.e. sentences) are filtered in or out.

        The specific semantics of what it means for this function to evaluate True or False are defined by the `_write`
        function.

        Args:
            sent: an object corresponding to the basic atoms of the corpus (typically sentences). The type of this
            argument must match that generated by `_get_sents` and expected by `_write`.

        Returns:
            True if the input atom should be "excluded" from the output corpus, and False otherwise.
        """

    @abstractmethod
    def _get_sents(self) -> Generator[T, None, None]:
        """Generator for the entities that are the atoms of the input corpus- typically sentences or similar.

        The type of return value of this generator must match that expected by `_exclude_sent` and `write`.

        Returns:
            A generator over the atoms of the corpus. The type of this argument must match that expected by
            `_exclude_sent` and `_write`.
        """

    @abstractmethod
    def _write(self, sent: T, reject: bool):
        """Process the writing to disk of a given input atom based on the given predicate evaluation value.

        For example, subclasses may write the sentence to one file if reject is True and another if it is False, or
        they may only write accepted sentences to file, or anything else.

        Args:
            sent: an object corresponding to the basic atoms of the corpus (typically sentences). The type of this
            argument must match that expected by `_exclude_sent` and generated by `_get_sents`.
            reject: boolean governing how this sentence is sorted.
        """

class CorpusFilterTextFileWriter(CorpusFilterWriter[T]):
    """Reads in a corpus, partitions it based on some predicate, and writes one or more of the partitioned corpuses to
    normal text file(s).

    Optionally, subclasses of this class may define a protocol for converting the type of the input corpus' atoms to
    a string value, e.g. if the input corpus' atoms consist of structured or annotated data.

    It is recommended that this class and its subclasses be used with a `with` block to ensure that the output file
    handles are properly closed on garbage collection or program exit.
    """
    def __init__(self, f_accept_out_path: str, f_reject_out_path: Optional[str] = None):
        """Constructor for CorpusFilterTextFileWriter.

        Args:
            f_accept_out_path: Path to where sentences for which the predicate evaluates False should be written
            f_reject_out_path:
                Path to where sentences for which the predicate evaluates False should be written. Optional; if `None`,
                rejected sentences will be discarded.
        """
        self._f_accept_out = open(f_accept_out_path, 'w')
        if f_reject_out_path: 
            self._f_reject_out = open(f_reject_out_path, 'w')
        else:
            self._f_reject_out = None

    def close(self):
        """Do file handle cleanup so this class can be used in a `with` block."""
        if self._f_accept_out is not None:
            self._f_accept_out.close()
        if self._f_reject_out is not None:
            self._f_accept_out.close()

        self._f_accept_out = None
        self._f_reject_out = None

    def _sent_to_str(self, sent: T) -> str:
        """Method that subclasses may override if the type of input corpus' atoms are not strings or otherwise require
        preprocessing prior to being written to disk.

        Args:
            sent: One of the basic atoms of the corpus (typically sentences).
        Returns:
            A string that can be written to file in normal `w` mode.
        """
        return sent

    def _write(self, sent: T, reject: bool):
        """Write a sentence to disk based on the given predicate evaluation value.

        Invokes `_sent_to_str` to do any preprocessing of the raw input sentences, and then writes the result to disk.

        Args:
            sent: an object corresponding to the basic atoms of the corpus (typically sentences). The type of this
            argument must match that expected by `_exclude_sent` and generated by `_get_sents`.
            reject: boolean governing how this sentence is sorted.
        """
        sent_str = self._sent_to_str(sent)
        out_line = f'{sent_str}\n'
        if not reject:
            self._f_accept_out.write(out_line)
        elif reject and self._f_reject_out:
            self._f_reject_out.write(out_line)

class PickleStanzaDocCorpusFilterWriter(CorpusFilterTextFileWriter[StanzaSentence]):
    """Reads in a corpus of pickled `stanza.Document` objects, partitions it based on some predicate, and writes one
    or more of the partitioned corpuses to file.

    The output sentences are the plaintext, that is, the `text` attribute of Stanza's `Sentence` class.

    As this is a subclass of CorpusFilterTextFileWriter, subclasses or instances of this class may choose to write only
    accepted sentences to file, or to write accepted sentences to one file and rejected ones to a different one.

    Under the hood, uses a thin wrapper around `nltk.corpus.reader.util.PickleCorpusView` to lazily load the pickled
    data as needed.
    """
    def __init__(
        self,
        f_in: str,
        f_accept_out_path: str,
        f_reject_out_path: Optional[str] = None,
        doc_block_size: int = 1,):
        """Constructor for PickleStanzaDocCorpusFilterWriter.

        Args:
            f_in: Path to the file containing the pickled `stanza.Document` objects.
            f_accept_out_path: Path to where sentences for which the predicate evaluates False should be written.
            f_reject_out_path:
                Path to where sentences for which the predicate evaluates False should be written. Optional; if `None`,
                rejected sentences will be discarded.
            doc_block_size: the number of `stanza.Document` objects that should be unpickled and processed at a time.
        """
        super().__init__(f_accept_out_path, f_reject_out_path)

        self._corpus_view = PickleStanzaDocCorpusView(f_in, doc_block_size)

    def _sent_to_str(self, sent: StanzaSentence) -> str:
        """Returns the text of a stanza `Sentence` object as a preprocessing step before writing to file.

        Args:
            sent: A stanza `Sentence` object.
        Returns:
            A string that can be written to file in normal `w` mode.
        """
        return sent.text

    def _get_sents(self) -> Generator[StanzaSentence, None, None]:
        """Generator for stanza `Sentence` objects from `stanza.Document` objects deserialized in batches from a corpus.

        A wrapper around a `PickleStanzaDocCorpusView` object, which itself wraps NLTK's `PickleCorpusView`.

        Returns:
            A generator over the corpus, as stanza `Sentence` objects.
        """
        for sent in self._corpus_view:
            yield sent
